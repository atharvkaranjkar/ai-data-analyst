# ğŸ§  Personal AI Data Analyst

An AI-powered data analysis application built with **Streamlit** that allows users to upload datasets and ask **natural language questions** to generate **insights, visualizations, and recommendations** using **AWS Bedrock LLMs**.

This project demonstrates how to combine **rule-based analytics**, **semantic intent detection**, and **LLM-powered reasoning** in a production-ready, cloud-deployed application.

---

## ğŸš€ Key Features

- Upload **CSV / Excel / JSON** datasets
- Automatic dataset understanding (schema, types, samples)
- Natural language queries for:
  - Summaries
  - Trends
  - Distributions
  - Anomaly detection
  - Business recommendations
- **Auto-generated visualizations** based on user intent
- **AWS Bedrock LLM integration** (Amazon Nova Lite)
- Optional **local LLM support** (Ollama) for development
- Cloud-ready deployment on **Streamlit Cloud**

---

## ğŸ§  How the App Works (Architecture)

The app follows a **three-layer decision pipeline**:

### 1ï¸âƒ£ Intent Detection
User prompts are classified into:
- **Simple** â†’ deterministic stats (rows, columns)
- **Visual** â†’ charts & distributions
- **Analysis** â†’ insights & recommendations

### 2ï¸âƒ£ Data-Aware Reasoning
- Dataset schema and samples are passed to the LLM
- The LLM returns either:
  - A **structured visualization plan (JSON)**, or
  - A **textual analytical response**

### 3ï¸âƒ£ Safe Execution
- The app validates LLM output
- Charts are rendered using Streamlit primitives
- No unsafe code execution (`exec` avoided)

---

## ğŸ“Š Example Use Cases

- *â€œWhat is the gender distribution across departments and job roles?â€*
- *â€œAnalyze salary trends over timeâ€*
- *â€œDetect and visualize anomalies in sensor dataâ€*
- *â€œRecommend actions to improve system reliabilityâ€*

---

## â˜ï¸ LLM & Cloud Support

### Cloud (Production)
- **AWS Bedrock**
  - Current model: **Amazon Nova Lite** (`amazon.nova-lite-v1:0`)
  - Region: `us-east-1` (configurable via `AWS_REGION`)

### Local (Development)
- **Ollama**
- Disabled automatically on Streamlit Cloud

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **Streamlit**
- **Pandas / NumPy**
- **AWS Bedrock (boto3)**
- **JSON-based LLM planning**
- **GitHub + Streamlit Cloud**

---

## ğŸ“¦ Requirements

See `requirements.txt` for complete dependencies. Key packages:
- `streamlit` - UI framework
- `pandas` / `numpy` - Data processing
- `boto3` - AWS SDK for Bedrock access

---

## ğŸ” Secrets Configuration

### Local Development
Create `.streamlit/secrets.toml` in your project root:

```toml
AWS_ACCESS_KEY_ID = "your_access_key_here"
AWS_SECRET_ACCESS_KEY = "your_secret_key_here"
AWS_REGION = "us-east-1"
```

A template file (`.streamlit/secrets.example.toml`) is provided for reference.

### Cloud Deployment (Streamlit Cloud)
Set these in **Streamlit Cloud â†’ App Settings â†’ Secrets** using the same format as above.

âš ï¸ **Never commit `secrets.toml` to GitHub** â€” it's already in `.gitignore`

---

## â–¶ï¸ Run Locally

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Setup credentials:**
   - Copy `.streamlit/secrets.example.toml` to `.streamlit/secrets.toml`
   - Add your AWS credentials

3. **Run the app:**
   ```bash
   streamlit run app.py
   ```

4. **Access:** Open `http://localhost:8501` in your browser

(Optional) Install Ollama for local LLM fallback testing.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app.py                        # Streamlit UI & routing logic
â”œâ”€â”€ analyst.py                    # LLM abstraction layer & analytics
â”œâ”€â”€ aws_llm.py                    # AWS Bedrock integration
â”œâ”€â”€ .streamlit/
â”‚   â”œâ”€â”€ secrets.example.toml      # Template for local secrets
â”‚   â””â”€â”€ secrets.toml              # Local credentials (not in git)
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore                    # Git ignore rules
â””â”€â”€ README.md                     # This file
```

---

## ğŸ§ª Design Principles

- **Intent-driven analytics**, not prompt-specific hacks
- **LLM as planner**, not executor
- **Rule-based first**, LLM only when needed
- **Cloud-first**, stateless execution
- **Safe parsing & validation** of LLM output

---

## ğŸ“„ Resume Description (2â€“3 Lines)

> Built a cloud-deployed AI data analysis tool using Streamlit and AWS Bedrock that interprets natural language queries to generate insights and visualizations. Implemented semantic intent detection and LLM-driven visualization planning for scalable, production-safe analytics.

---

## ğŸ Status

âœ… Feature-complete  
âœ… Cloud deployed  
âœ… Resume & interview ready  

---

## ğŸ“œ License

MIT License
